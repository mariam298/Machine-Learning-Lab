{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SV_obQ1Lual3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(data_folder):\n",
        "    texts, labels = [], []\n",
        "    for category_folder in os.listdir(data_folder):\n",
        "        category_path = os.path.join(data_folder, category_folder)\n",
        "        if os.path.isdir(category_path):\n",
        "            for review_file in glob.glob(os.path.join(category_path, \"*.txt\")):\n",
        "                with open(review_file, 'r', encoding='utf-8') as file:\n",
        "                    texts.append(file.read())\n",
        "                    labels.append(category_folder)\n",
        "    return texts, labels"
      ],
      "metadata": {
        "id": "m_ltxuLMuoJg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_folder = \"path_to_train_data\"\n",
        "test_folder = \"path_to_test_data\""
      ],
      "metadata": {
        "id": "Wildk1YSuo9C"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install beautifulsoup4 requests\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qjq52nf5uzk-",
        "outputId": "7aff4798-5b03-4e46-fcee-4b5e03943215"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.12.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url = 'https://www.yelp.com/search?find_desc=restaurants&find_loc=San+Francisco'\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "reviews = soup.find_all('p', class_='comment__373c0__2rR1n')  # You will need to find the correct class\n",
        "for review in reviews:\n",
        "    print(review.get_text())\n"
      ],
      "metadata": {
        "id": "-wWCj4d8vMGT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "\n",
        "reviews_data = []\n",
        "labels = []\n",
        "\n"
      ],
      "metadata": {
        "id": "XmfusK3qvPHL"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for review in reviews:\n",
        "    review_text = review.get_text()\n",
        "    reviews_data.append(review_text)\n",
        "\n",
        "    labels.append('positive' if 'good' in review_text else 'negative')"
      ],
      "metadata": {
        "id": "RLKJQ0u3vjvn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('reviews.csv', mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(['Review', 'Sentiment'])  # Column headers\n",
        "    for review, label in zip(reviews_data, labels):\n",
        "        writer.writerow([review, label])"
      ],
      "metadata": {
        "id": "ETunIxsmvngC"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import string"
      ],
      "metadata": {
        "id": "oCNEs5EtvuLk"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    return text"
      ],
      "metadata": {
        "id": "HixhqvievzB9"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews_data_cleaned = [preprocess_text(review) for review in reviews_data]"
      ],
      "metadata": {
        "id": "JbQDzEQ6v-8U"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(reviews_data[:10])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbUeqNvcwC9f",
        "outputId": "a0973da5-f0ba-4442-90f3-ffbe3c611b87"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for review in reviews[:10]:  # Check first 10 reviews\n",
        "    print(review.get_text())"
      ],
      "metadata": {
        "id": "JeAHls16wQpB"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print out the raw HTML of the page to inspect structure\n",
        "print(soup.prettify()[:1000])  # Print first 1000 characters of HTML to understand the structure\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "trb4BjUawlHx",
        "outputId": "9374868e-5169-458a-bc73-6f4321a94d3f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<html lang=\"en\">\n",
            " <head>\n",
            "  <title>\n",
            "   yelp.com\n",
            "  </title>\n",
            "  <style>\n",
            "   #cmsg{animation: A 1.5s;}@keyframes A{0%{opacity:0;}99%{opacity:0;}100%{opacity:1;}}\n",
            "  </style>\n",
            " </head>\n",
            " <body style=\"margin:0\">\n",
            "  <p id=\"cmsg\">\n",
            "   Please enable JS and disable any ad blocker\n",
            "  </p>\n",
            "  <script data-cfasync=\"false\">\n",
            "   var dd={'rt':'c','cid':'AHrlqAAAAAMAlxd6upPSP7kAIhDejg==','hsh':'3BD2468BAE4D73BEA0B5DE8314D745','t':'bv','s':46977,'e':'f1669ea970b6848710882afeca5d541f5c144474b7d8ae1d68c2f3b5992ef17c','host':'geo.captcha-delivery.com','cookie':'hKc8LPnemeP8t6xyMWs98~ZmPGtZTbFwnuKk7Ko043Yq~dt5mB0c__8yZZYNFZc4sSAuPs~X9Vl9knjfMoVWTbEi4pOMgpJqPZrLvPEusyGwTqcMo8zfvnUT2Hs8LXOA'}\n",
            "  </script>\n",
            "  <script data-cfasync=\"false\" src=\"https://ct.captcha-delivery.com/c.js\">\n",
            "  </script>\n",
            " </body>\n",
            "</html>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Correct class for reviews (update based on the actual class you find)\n",
        "reviews = soup.find_all('p', class_='review__373c0__2rR1n')  # Adjust class as necessary\n",
        "\n",
        "# Print out the reviews to verify scraping\n",
        "for review in reviews[:10]:\n",
        "    print(review.get_text())\n"
      ],
      "metadata": {
        "id": "a2S8ja4Pwn0f"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url = 'https://www.yelp.com/search?find_desc=restaurants&find_loc=San+Francisco'\n",
        "response = requests.get(url)\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "# Attempt to find the review text (this might require updating the class name)\n",
        "reviews = soup.find_all('p')  # This is a more general approach, adjust based on actual HTML structure\n",
        "\n",
        "# Print the first few reviews to verify\n",
        "for review in reviews[:10]:\n",
        "    print(review.get_text())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WOvXZZZwrm1",
        "outputId": "cccea2b8-59e1-414e-9d49-05713390fdb0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please enable JS and disable any ad blocker\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Simplified preprocessing function\n",
        "def preprocess_text_simple(text):\n",
        "    text = text.lower().strip()  # Convert to lowercase and strip extra spaces\n",
        "    return text\n",
        "\n",
        "# Preprocess the reviews\n",
        "reviews_data_cleaned = [preprocess_text_simple(review.get_text()) for review in reviews]\n",
        "\n",
        "# Check the cleaned reviews\n",
        "print(reviews_data_cleaned[:10])  # Inspect the cleaned data\n",
        "\n",
        "# Proceed with vectorization if the reviews are not empty\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "X = vectorizer.fit_transform(reviews_data_cleaned)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RgVEyMG_wuws",
        "outputId": "1b9fd8ff-e3ce-4a6f-9445-ae9b9273c5f2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['please enable js and disable any ad blocker']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install selenium\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHa1-83VwyDH",
        "outputId": "a6fab163-34eb-4f7f-d972-22a4677f8cdd"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting selenium\n",
            "  Downloading selenium-4.27.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (2.3.0)\n",
            "Collecting trio~=0.17 (from selenium)\n",
            "  Downloading trio-0.28.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting trio-websocket~=0.9 (from selenium)\n",
            "  Downloading trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (2024.12.14)\n",
            "Requirement already satisfied: typing_extensions~=4.9 in /usr/local/lib/python3.10/dist-packages (from selenium) (4.12.2)\n",
            "Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.10/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (24.3.0)\n",
            "Collecting sortedcontainers (from trio~=0.17->selenium)\n",
            "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (3.10)\n",
            "Collecting outcome (from trio~=0.17->selenium)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from trio~=0.17->selenium) (1.2.2)\n",
            "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
            "Downloading selenium-4.27.1-py3-none-any.whl (9.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio-0.28.0-py3-none-any.whl (486 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.3/486.3 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
            "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Installing collected packages: sortedcontainers, wsproto, outcome, trio, trio-websocket, selenium\n",
            "Successfully installed outcome-1.3.0.post0 selenium-4.27.1 sortedcontainers-2.4.0 trio-0.28.0 trio-websocket-0.11.1 wsproto-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chrome_driver_path = r'C:\\path\\to\\chromedriver.exe'\n"
      ],
      "metadata": {
        "id": "tHH6lZO4xOTt"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "if not os.path.exists(chrome_driver_path):\n",
        "    print(f\"ChromeDriver not found at {chrome_driver_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnArPuSVxWqT",
        "outputId": "bc1e8d7d-d942-486a-b12e-8cea5831d9e6"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChromeDriver not found at C:\\path\\to\\chromedriver.exe\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Define the folder paths\n",
        "train_folder = 'train_folder'\n",
        "test_folder = 'test_folder'\n",
        "\n",
        "# Create the folders if they do not exist\n",
        "os.makedirs(os.path.join(train_folder, 'positive'), exist_ok=True)\n",
        "os.makedirs(os.path.join(train_folder, 'negative'), exist_ok=True)\n",
        "os.makedirs(os.path.join(test_folder, 'positive'), exist_ok=True)\n",
        "os.makedirs(os.path.join(test_folder, 'negative'), exist_ok=True)\n",
        "\n",
        "print(\"Folders created successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dW-WfyG_yVaP",
        "outputId": "b193ddcc-e502-4ea5-c16a-9c91a6e88f85"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folders created successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save a sample positive review in the 'positive' folder inside train folder\n",
        "with open(os.path.join(train_folder, 'positive', 'review1.txt'), 'w') as file:\n",
        "    file.write(\"The food was absolutely delicious and the service was fantastic. I would definitely recommend this restaurant to everyone!\")\n"
      ],
      "metadata": {
        "id": "aibSX8mxzT3k"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save a sample negative review in the 'negative' folder inside train folder\n",
        "with open(os.path.join(train_folder, 'negative', 'review1.txt'), 'w') as file:\n",
        "    file.write(\"The restaurant was overpriced, and the food was bland. Not worth the money.\")\n"
      ],
      "metadata": {
        "id": "9Twa-4P-zuY-"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install requests beautifulsoup4\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpqQ_ysDzy1Y",
        "outputId": "3763f7e1-2236-489e-d7c1-30eccde3a0ce"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.12.14)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import os\n",
        "\n",
        "# Create the folder structure\n",
        "train_folder = 'train_folder'\n",
        "os.makedirs(os.path.join(train_folder, 'positive'), exist_ok=True)\n",
        "os.makedirs(os.path.join(train_folder, 'negative'), exist_ok=True)\n",
        "\n",
        "# Set up the URL for Yelp (change to the restaurant you want to scrape)\n",
        "url = 'https://www.yelp.com/biz/restaurant-name-city'\n",
        "response = requests.get(url)\n",
        "\n",
        "# Parse the HTML content\n",
        "soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "# Find all reviews on the page (adjust the class name according to the website structure)\n",
        "reviews = soup.find_all('p', class_='comment__373c0__2rR1n')  # The correct class needs to be inspected\n",
        "\n",
        "# Save the reviews in appropriate folders\n",
        "for i, review in enumerate(reviews):\n",
        "    review_text = review.get_text()\n",
        "\n",
        "    # Assume reviews with more than 50 characters are positive (this is just a placeholder; adjust as needed)\n",
        "    if len(review_text) > 50:\n",
        "        folder = 'positive'\n",
        "    else:\n",
        "        folder = 'negative'\n",
        "\n",
        "    # Save the review as a text file\n",
        "    file_path = os.path.join(train_folder, folder, f'review_{i+1}.txt')\n",
        "    with open(file_path, 'w') as file:\n",
        "        file.write(review_text)\n",
        "\n",
        "    print(f\"Saved review_{i+1}.txt in {folder} folder.\")\n",
        "\n",
        "print(\"Finished saving reviews.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJBypyaT0J4T",
        "outputId": "5775c676-c526-4d0c-e283-57519f4a0f0d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished saving reviews.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def load_data(data_folder):\n",
        "    texts, labels = [], []\n",
        "    for category in ['positive', 'negative']:  # Categories: positive and negative\n",
        "        category_folder = os.path.join(data_folder, category)\n",
        "        for filename in os.listdir(category_folder):\n",
        "            with open(os.path.join(category_folder, filename), 'r') as file:\n",
        "                texts.append(file.read())  # Read the review text\n",
        "                labels.append(category)  # Assign the label (positive/negative)\n",
        "    return texts, labels\n",
        "\n",
        "# Load training data\n",
        "train_folder = 'train_folder'  # Folder where reviews are stored\n",
        "train_texts, train_labels = load_data(train_folder)\n",
        "\n",
        "print(f\"Loaded {len(train_texts)} training samples.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9UULD8t0QSi",
        "outputId": "74607486-7741-4a52-ac3d-8ef9afeddbb4"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 2 training samples.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Vectorize the reviews using TF-IDF\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "X_train = vectorizer.fit_transform(train_texts)  # Train TF-IDF on the training data\n",
        "\n",
        "print(f\"Shape of feature matrix: {X_train.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2904N7R0kGr",
        "outputId": "16dab8fa-79be-4bec-d95a-b942b136c858"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of feature matrix: (2, 12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Train the Naive Bayes classifier\n",
        "classifier = MultinomialNB()\n",
        "classifier.fit(X_train, train_labels)\n",
        "\n",
        "print(\"Model trained successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMf8NPtN0pC5",
        "outputId": "abce0c20-55ba-4fdc-f050-2e7afeaf6bdd"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model trained successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check loaded data\n",
        "print(f\"Loaded {len(test_texts)} test samples.\")\n",
        "print(f\"Test texts: {test_texts[:5]}\")  # Print first 5 test texts to verify data\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEC5bEYj0tPN",
        "outputId": "ee11d0a6-7fe2-4193-e577-8e38b1eeae11"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 0 test samples.\n",
            "Test texts: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(data_folder):\n",
        "    texts, labels = [], []\n",
        "    for category in ['positive', 'negative']:  # Categories: positive and negative\n",
        "        category_folder = os.path.join(data_folder, category)\n",
        "        if not os.path.exists(category_folder):\n",
        "            print(f\"Warning: {category_folder} does not exist.\")\n",
        "            continue\n",
        "        for filename in os.listdir(category_folder):\n",
        "            file_path = os.path.join(category_folder, filename)\n",
        "            if os.path.isfile(file_path):\n",
        "                with open(file_path, 'r') as file:\n",
        "                    texts.append(file.read())\n",
        "                    labels.append(category)\n",
        "    return texts, labels\n",
        "\n",
        "# Load test data\n",
        "test_folder = 'test_folder'  # Folder with test data\n",
        "test_texts, test_labels = load_data(test_folder)\n",
        "\n",
        "# Check loaded data\n",
        "print(f\"Loaded {len(test_texts)} test samples.\")\n",
        "if len(test_texts) > 0:\n",
        "    print(f\"First 5 test texts: {test_texts[:5]}\")  # Check the first 5 reviews\n",
        "\n",
        "# Proceed if test data is not empty\n",
        "if len(test_texts) > 0:\n",
        "    # Vectorize the test data\n",
        "    X_test = vectorizer.transform(test_texts)\n",
        "\n",
        "    # Make predictions on the test data\n",
        "    predictions = classifier.predict(X_test)\n",
        "\n",
        "    # Print out a few sample predictions vs true labels\n",
        "    for i in range(5):\n",
        "        print(f\"True label: {test_labels[i]}, Predicted label: {predictions[i]}\")\n",
        "else:\n",
        "    print(\"No test data available. Please check the test folder.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gk_ZBth50yS1",
        "outputId": "0acc9ac1-f592-48d7-d3f1-b757807a0bd5"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 0 test samples.\n",
            "No test data available. Please check the test folder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Loaded {len(test_texts)} test samples.\")\n",
        "print(f\"Test labels: {test_labels[:5]}\")  # Print first 5 labels for debugging\n",
        "print(f\"Predictions: {predictions[:5]}\")  # Print first 5 predictions for debugging\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYCKTWba23MB",
        "outputId": "723a69e2-3ab7-4776-e5fa-d8c81384bf2d"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 2 test samples.\n",
            "Test labels: ['positive', 'negative']\n",
            "Predictions: ['positive' 'positive']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if len(test_labels) > 0 and len(predictions) > 0:\n",
        "    # Print out a few sample predictions vs true labels\n",
        "    for i in range(min(5, len(test_labels))):  # Ensure no out-of-range access\n",
        "        print(f\"True label: {test_labels[i]}, Predicted label: {predictions[i]}\")\n",
        "else:\n",
        "    print(\"No test data or predictions available. Please check the test folder or model.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNZOVjWx3FBC",
        "outputId": "1ca74698-569b-4e0d-bb13-5c357e74ebd8"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True label: positive, Predicted label: positive\n",
            "True label: negative, Predicted label: positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Length of test labels: {len(test_labels)}\")\n",
        "print(f\"Length of predictions: {len(predictions)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdWAjoey3KAD",
        "outputId": "6a8a8c3e-b0e9-4689-94cb-6b91486e74ad"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of test labels: 2\n",
            "Length of predictions: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check loaded test data\n",
        "print(f\"Loaded {len(test_texts)} test samples.\")\n",
        "if len(test_texts) > 0:\n",
        "    # Vectorize the test data\n",
        "    X_test = vectorizer.transform(test_texts)\n",
        "\n",
        "    # Make predictions on the test data\n",
        "    predictions = classifier.predict(X_test)\n",
        "\n",
        "    # Check if predictions and labels have the same length\n",
        "    print(f\"Length of test labels: {len(test_labels)}\")\n",
        "    print(f\"Length of predictions: {len(predictions)}\")\n",
        "\n",
        "    if len(test_labels) > 0 and len(predictions) > 0:\n",
        "        # Print out a few sample predictions vs true labels\n",
        "        for i in range(min(5, len(test_labels))):  # Ensure no out-of-range access\n",
        "            print(f\"True label: {test_labels[i]}, Predicted label: {predictions[i]}\")\n",
        "    else:\n",
        "        print(\"No predictions or test data available. Please check the test folder or model.\")\n",
        "else:\n",
        "    print(\"No test data available. Please check the test folder.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MGIgHYs3Okb",
        "outputId": "fc9bb3c9-8d2b-4756-92f8-7e152c554e7d"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 2 test samples.\n",
            "Length of test labels: 2\n",
            "Length of predictions: 2\n",
            "True label: positive, Predicted label: positive\n",
            "True label: negative, Predicted label: positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "# Calculate accuracy, precision, and recall\n",
        "accuracy = accuracy_score(test_labels, predictions)\n",
        "precision = precision_score(test_labels, predictions, pos_label='positive')\n",
        "recall = recall_score(test_labels, predictions, pos_label='positive')\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zH06JHHq3TAA",
        "outputId": "4295d121-2571-4128-c328-2421b3115919"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.50\n",
            "Precision: 0.50\n",
            "Recall: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(test_labels)):\n",
        "    if test_labels[i] != predictions[i]:\n",
        "        print(f\"Sample {i+1}: True label: {test_labels[i]}, Predicted label: {predictions[i]}\")\n",
        "        print(f\"Review text: {test_texts[i]}\")\n",
        "        print(\"-\" * 50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WO7a8WmU3lAF",
        "outputId": "b17bfe2a-9523-437b-e32d-3848aeb69df6"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample 2: True label: negative, Predicted label: positive\n",
            "Review text: Terrible experience. The food was bland, and the service was slow. I would not recommend this place to anyone.\n",
            "\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Step 2: Vectorize the text\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "X_train = vectorizer.fit_transform(train_texts)\n",
        "X_test = vectorizer.transform(test_texts)\n",
        "\n",
        "# Step 3: Train the Naive Bayes classifier\n",
        "classifier = MultinomialNB()\n",
        "classifier.fit(X_train, train_labels)\n",
        "\n",
        "# Step 4: Test the model\n",
        "predictions = classifier.predict(X_test)\n",
        "\n",
        "# Step 5: Evaluate performance\n",
        "accuracy = accuracy_score(test_labels, predictions)\n",
        "precision = precision_score(test_labels, predictions, pos_label='positive', average='binary')\n",
        "recall = recall_score(test_labels, predictions, pos_label='positive', average='binary')\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "\n",
        "# Step 6: Save the model (optional)\n",
        "joblib.dump(classifier, 'naive_bayes_classifier.pkl')\n",
        "joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UN13w0s23q8R",
        "outputId": "5d69f15a-ff70-4ae4-8579-5acedfe7c478"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5000\n",
            "Precision: 0.5000\n",
            "Recall: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tfidf_vectorizer.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "# Sample training data (replace with your actual train data)\n",
        "train_texts = [\"Great food and service!\", \"Terrible experience\", \"Loved the ambiance and the food\", \"Bad food, bad service\"]\n",
        "train_labels = ['positive', 'negative', 'positive', 'negative']\n",
        "\n",
        "# Initialize vectorizer and transform train data\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "X_train = vectorizer.fit_transform(train_texts)\n",
        "\n",
        "# Initialize and train the Naive Bayes classifier\n",
        "classifier = MultinomialNB()\n",
        "classifier.fit(X_train, train_labels)\n",
        "\n",
        "# Sample test data (replace with your actual test data)\n",
        "test_texts = [\"Excellent food and service\", \"Worst experience ever\"]\n",
        "test_labels = ['positive', 'negative']\n",
        "\n",
        "# Vectorize the test data\n",
        "X_test = vectorizer.transform(test_texts)\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions = classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the performance\n",
        "accuracy = accuracy_score(test_labels, predictions)\n",
        "precision = precision_score(test_labels, predictions, pos_label='positive')\n",
        "recall = recall_score(test_labels, predictions, pos_label='positive')\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "\n",
        "# Display predictions\n",
        "for i in range(len(test_texts)):\n",
        "    print(f\"Review: {test_texts[i]}\")\n",
        "    print(f\"True label: {test_labels[i]}, Predicted label: {predictions[i]}\")\n",
        "    print(\"-\" * 50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHFzyHbr35tr",
        "outputId": "7541e07d-2808-4af5-fff0-4dc3e681b165"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.00\n",
            "Precision: 1.00\n",
            "Recall: 1.00\n",
            "Review: Excellent food and service\n",
            "True label: positive, Predicted label: positive\n",
            "--------------------------------------------------\n",
            "Review: Worst experience ever\n",
            "True label: negative, Predicted label: negative\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iXa4Fw974SxJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}